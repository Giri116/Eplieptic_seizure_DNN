{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df1f8a98-819e-412a-b8f9-0e7b882f8e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from pandas import read_csv\n",
    "from pandas import concat\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5ee0863-f464-4cd9-a79d-e6905d1a0531",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abnormal01_aaaaabdo_s003_t000.edf.csv',\n",
       " 'abnormal02_aaaaaddm_s006_t000.edf.csv',\n",
       " 'abnormal03_aaaaadeu_s002_t000.edf.csv',\n",
       " 'abnormal04_aaaaadkb_s002_t000.edf.csv',\n",
       " 'abnormal06_aaaaagsc_s006_t001.edf.csv',\n",
       " 'abnormal07_aaaaagvx_s002_t000.edf.csv',\n",
       " 'abnormal08_aaaaagvx_s003_t001.edf.csv',\n",
       " 'abnormal_aaaaabuv_s002_t000.edf.csv',\n",
       " 'abnornal05_aaaaagsc_s003_t001.edf.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ps_files = os.listdir(os.path.join(os.getcwd(),'Datasets','Abnormal'))\n",
    "ps_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd9ff9fb-445e-4b0a-93fc-ef2f0b2eb6f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['normal01_aaaaacad_s003_t000.edf.csv',\n",
       " 'normal02_aaaaacby_s004_t000.edf.csv',\n",
       " 'normal03_aaaaadjk_s002_t000.edf.csv',\n",
       " 'normal04_aaaaadsm_s002_t001.edf.csv',\n",
       " 'normal_aaaaaayx_s002_t000.edf.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ng_files = os.listdir(os.path.join(os.getcwd(),'Datasets','Normal'))\n",
    "ng_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6bf353ff-2c3c-4fb3-a604-7ceb6b6d073e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_data(files, state):\n",
    "#Import dataframe\n",
    "    cols = [I for I in range(32)]\n",
    "    datasets = []\n",
    "    for file in files:\n",
    "        ps_df = read_csv(os.path.join(os.getcwd(),'Datasets', str(state),file))\n",
    "        ps_df = ps_df[ps_df.columns[:32]]\n",
    "        if state.lower() == 'abnormal':\n",
    "            ps_df['label'] = np.ones(ps_df[ps_df.columns[0]].shape)\n",
    "        elif state.lower() == 'normal':\n",
    "            ps_df['label'] = np.zeros(ps_df[ps_df.columns[0]].shape)\n",
    "        try:\n",
    "            ps_df.columns==cols\n",
    "            print(file)\n",
    "            # Replace these with your actual data\n",
    "            if ps_df.shape[1]==33:\n",
    "                X_train_dataset = ps_df.drop('label',axis=1)\n",
    "                Y_train_dataset =  ps_df['label']\n",
    "                datasets.append((X_train_dataset, Y_train_dataset))\n",
    "        except Exception as e:\n",
    "            pass\n",
    "        cols = ps_df.columns\n",
    "    return datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85b90f13-1698-41f0-bcb5-1b9af71a31d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "abnormal02_aaaaaddm_s006_t000.edf.csv\n",
      "abnormal04_aaaaadkb_s002_t000.edf.csv\n",
      "abnormal06_aaaaagsc_s006_t001.edf.csv\n",
      "abnormal07_aaaaagvx_s002_t000.edf.csv\n",
      "abnornal05_aaaaagsc_s003_t001.edf.csv\n",
      "normal02_aaaaacby_s004_t000.edf.csv\n",
      "normal03_aaaaadjk_s002_t000.edf.csv\n",
      "normal04_aaaaadsm_s002_t001.edf.csv\n",
      "normal_aaaaaayx_s002_t000.edf.csv\n"
     ]
    }
   ],
   "source": [
    "ps = import_data(ps_files, 'Abnormal')\n",
    "ng = import_data(ng_files, 'Normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6b5660f4-f436-444a-a079-a5f77b643e3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 4)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = []\n",
    "len(ps), len(ng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ba2b4c9-1d46-4de9-ba5d-e3538a0165c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "for p in ps:\n",
    "    print(len(p))\n",
    "    datasets.append(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a09cbae5-0f8f-4c67-9a4b-7dc54fd4dbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "2\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for n in ng:\n",
    "    print(len(n))\n",
    "    datasets.append(n)\n",
    "len(datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7ed61966-b2e8-4a68-93ab-6ae37ceb8895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2520750, 32), (2520750,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine all datasets into a single dataset\n",
    "X_train_combined = np.concatenate([dataset[0] for dataset in datasets], axis=0)\n",
    "Y_train_combined = np.concatenate([dataset[1] for dataset in datasets], axis=0)\n",
    "X_train_combined.shape, Y_train_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23947ffd-b9a8-4036-9f16-2273177a1c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_combined = scaler.fit_transform(X_train_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d8812e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['# EEG FP1-REF', 'EEG FP2-REF', 'EEG F3-REF', 'EEG F4-REF',\n",
       "       'EEG C3-REF', 'EEG C4-REF', 'EEG P3-REF', 'EEG P4-REF', 'EEG O1-REF',\n",
       "       'EEG O2-REF', 'EEG F7-REF', 'EEG F8-REF', 'EEG T3-REF', 'EEG T4-REF',\n",
       "       'EEG T5-REF', 'EEG T6-REF', 'EEG A1-REF', 'EEG A2-REF', 'EEG FZ-REF',\n",
       "       'EEG CZ-REF', 'EEG PZ-REF', 'EEG ROC-REF', 'EEG LOC-REF',\n",
       "       'EEG EKG1-REF', 'EMG-REF', 'EEG 26-REF', 'EEG 27-REF', 'EEG 28-REF',\n",
       "       'EEG 29-REF', 'EEG 30-REF', 'EEG T1-REF', 'EEG T2-REF', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = read_csv(\"test1.edf.csv\")\n",
    "test_df = test_df[test_df.columns[:32]]\n",
    "test_df['label'] = np.ones(test_df[test_df.columns[0]].shape)\n",
    "test_df.head()\n",
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0cfe08e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_df.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1f9334dc-dd33-41b5-a821-26a28bb0e959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to create the DNN model\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    # Modify the input dimension of the first layer to match the number of features in your input data (32 in this case)\n",
    "    # 30000\n",
    "    model.add(Dense(300, input_dim=32, activation='relu'))\n",
    "    # 15000\n",
    "    model.add(Dense(150, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    # 7500\n",
    "    model.add(Dense(75, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "486d19a7-59dd-4536-870d-c2ce36aee3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile the model for dataset 1\n",
    "model_dataset = create_model()\n",
    "model_dataset.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8e8fecc0-71b3-4f50-a9d3-62690976ac47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2520750, 32), (2520750,))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_combined.shape, Y_train_combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d195e8b9-dc47-47ab-9865-94dc11063523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the labels into one-hot encoding\n",
    "Y_train1_onehot = tf.keras.utils.to_categorical(Y_train_combined, num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6a8fcb9d-24f4-4e49-8ab4-c22f043c7813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset 1 into train and validation sets\n",
    "X_train1, X_val1, Y_train1, Y_val1 = train_test_split(X_train_combined, Y_train1_onehot, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3decdef3-584c-4270-a5f8-7c4b186e1b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((504150, 32), (504150, 2))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1 = test_df.drop('label',axis=1)\n",
    "Y_test1 = test_df['label']\n",
    "\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_test1, Y_test1, test_size=0.5, random_state=42)\n",
    "\n",
    "# Convert the test labels into one-hot encoding\n",
    "Y_test_onehot = tf.keras.utils.to_categorical(Y_test, num_classes=2)\n",
    "\n",
    "X_val1.shape, Y_val1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb2f77c1-d439-45e7-a4a2-9f46b6503995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "15755/15755 [==============================] - 54s 3ms/step - loss: 0.2486 - accuracy: 0.8960 - val_loss: 0.1554 - val_accuracy: 0.9378\n",
      "Epoch 2/3\n",
      "15755/15755 [==============================] - 49s 3ms/step - loss: 0.1612 - accuracy: 0.9374 - val_loss: 0.1293 - val_accuracy: 0.9489\n",
      "Epoch 3/3\n",
      "15755/15755 [==============================] - 51s 3ms/step - loss: 0.1401 - accuracy: 0.9463 - val_loss: 0.1180 - val_accuracy: 0.9536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fc46e610070>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model on dataset 1\n",
    "model_dataset.fit(X_train1, Y_train1, epochs=3, batch_size=128, validation_data=(X_val1, Y_val1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "211191ba-8baf-456b-94c4-45aac98473f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4704/4704 [==============================] - 7s 1ms/step - loss: 0.1338 - accuracy: 1.0000\n",
      "Dataset 1 Validation Loss: 0.1338, Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on dataset 1\n",
    "loss, accuracy = model_dataset.evaluate(X_test, Y_test_onehot)\n",
    "print(f\"Dataset 1 Validation Loss: {loss:.4f}, Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0f97b960-877b-4048-8d62-117fc4b2dcc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4704/4704 [==============================] - 6s 1ms/step\n",
      "[[0.02009058 0.9799095 ]\n",
      " [0.02009208 0.979908  ]\n",
      " [0.0200946  0.9799054 ]\n",
      " ...\n",
      " [0.02005781 0.9799422 ]\n",
      " [0.02009596 0.97990406]\n",
      " [0.02008194 0.97991806]]\n"
     ]
    }
   ],
   "source": [
    "pred = model_dataset.predict(X_test)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "406efaf2-a554-4a32-a8c9-819e65976fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "# Plot the model architecture\n",
    "plot_model(model_dataset, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
